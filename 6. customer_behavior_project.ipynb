{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d94668bf-b4de-4abd-887e-151425d7d16c",
   "metadata": {},
   "source": [
    "# Анализ поведения клиентов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd95017-4b7b-4bf4-b08f-5b52c49221d6",
   "metadata": {},
   "source": [
    "Оператор мобильной связи «Мегалайн» выяснил: многие клиенты пользуются архивными тарифами. Нам необходимо построить систему, способную проанализировать поведение клиентов и предложить пользователям новый тариф: «Смарт» или «Ультра».\n",
    "\n",
    "В нашем распоряжении данные о поведении клиентов, которые уже перешли на эти тарифы. Нужно построить модель для задачи классификации, которая выберет подходящий тариф. Предобработка данных уже проведена.\n",
    "Необходимо построить модель с максимально большим значением accuracy. Чтобы считать проект успешным, нужно довести долю правильных ответов по крайней мере до 0.75. Далее проверим значение accuracy на тестовой выборке.\n",
    "\n",
    "**Описание данных:** \\\n",
    "Каждый объект в наборе данных — это информация о поведении одного пользователя за месяц.\n",
    "\n",
    "**Известно:** \\\n",
    "**сalls** — количество звонков,\\\n",
    "**minutes** — суммарная длительность звонков в минутах,\\\n",
    "**messages** — количество sms-сообщений,\\\n",
    "**mb_used** — израсходованный интернет-трафик в Мб,\\\n",
    "**is_ultra** — каким тарифом пользовался в течение месяца («Ультра» — 1, «Смарт» — 0).\n",
    "\n",
    "**Цель исследования:** Необходимо построить модель для задачи классификации, которая выберет подходящий тариф и построить модель с максимально большим значением accuracy. Необходимо довести долю правильных ответов по крайней мере до 0.75 и проверить значение accuracy на тестовой выборке.\n",
    "\n",
    "**Ход исследоввания:** Изучим файлы с данными users_behavior.csv. Разделим исходные данные на обучающую, валидационную и тестовую выборки. Исследуем качество разных моделей меняя гиперпараметры. Проверим качество модели на тестовой выборке. Проверим модели на вменяемость.\n",
    "\n",
    "**Исследование пройдет в шесть этапов:**\n",
    "\n",
    "1) Изучение общей информации о данных.\n",
    "2) Разделение исходных данных на выборки.\n",
    "3) Исследование качества моделей при изменении гиперпараметров.\n",
    "4) Проверка качества модели на тестовой выборке.\n",
    "5) Проверка модели на вменяемость.\n",
    "6) Общий вывод.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13af1138-ad3a-4c64-a6a3-5be1d9f95622",
   "metadata": {},
   "source": [
    "# 1. Откроем файл с данными и изучим общую информацию. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d7a57b-81c4-4915-a905-c8a3a213b084",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки. Считаем данные из csv-файла в датафрейм и сохраним в переменную data. Путь к файлам: /Users/Slava/Desktop/Яндекс Практикум учебные материалы/Проекты/Проект6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee96e70c-bb02-4715-9bde-16872c249f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем необходимые библиотеки\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats as st\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3426ac66-c085-42ee-86f8-6362527297b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# прочитаем данные из csv-файла в датафрейм и сохраним в переменную \n",
    "try:\n",
    "    data = pd.read_csv('/Users/Slava/Desktop/Яндекс Практикум учебные материалы/Проекты/Проект6./users_behavior.csv', sep = ',')\n",
    "except: \n",
    "     data = pd.read_csv('/datasets/users_behavior.csv', sep = ',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c5b9fbf-aecf-4c4c-a714-e2159f675d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ознакомимся с общей информацией о данных\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60b9f28-4c29-4c76-98ed-33b280458049",
   "metadata": {},
   "source": [
    "Типы данных корректы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7af8e705-ea70-46c2-93cb-a14767c39ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выведем первые 10 строк набора данных, ознакомимся с признаками и объектами\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55df02ac-bbb7-4c06-9fe2-fef0170e6226",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ознакомимся с описательной статистикой набора данных\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20e3d031-9f35-4a2b-b399-f54616852921",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# на всякий случай проверим пропуски в данных\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d5630f-f2ff-4610-ac8b-ddd53d1fe37b",
   "metadata": {},
   "source": [
    "В данных 3214 объектов, пропуски отсутствуют. Исходя из постановки задачи, целевым признаком является - 'is_ultra'. Он принимает значения 0 или 1, а значит, перед нами классическая задача бинарной классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a0335e-e9ef-4b47-950d-a0bd03d87b74",
   "metadata": {},
   "source": [
    "Оценим соотношение пользователей в наборе данных с тарифом 'ultra' и 'smart'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cf7b78e-824e-4ef4-b242-ea6dc9285ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['is_ultra'].value_counts()/len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d25726-821b-4bde-8bfd-7ca0ce46ab78",
   "metadata": {},
   "source": [
    "Значений - '1' в признаке 'is_ultra' порядка ~ 30%, что означает значения представлены неравномерно, что логично, как правило более продвинутым тарифом пользуется меньшее количество клиентов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b08650-4dd3-4e01-b9f9-d353656c966d",
   "metadata": {},
   "source": [
    "# 2. Разделение исходных данных на выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a35cb95f-f77f-42dc-b43b-9311fb26e547",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = data.drop(['is_ultra'], axis=1)\n",
    "target = data['is_ultra'] \n",
    "features.shape, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097e8022-2914-42f2-90c7-dfee0c443538",
   "metadata": {},
   "source": [
    "Разделим выборку на обучающую, валидационную и тестовую в отношении 3:1:1.\\\n",
    "Так же мы учтем неравномерность представления целевых признаков и используем параметр 'stratify'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2416d162-a754-4daf-b58d-24a21552853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сначала разобъем выборку на обучающую и 'осаточную' в пропорции 60/40,\n",
    "# применим 'stratify' для равномерного разделения значений в признаке.\n",
    "features_train, features_remaining, target_train, target_remaining = train_test_split(\n",
    "    features, target, test_size=0.4, random_state=12345, stratify=target)\n",
    "# разобъем 'остаточную' выборку на тестовую и валидационную в пропорциях 50/50, \n",
    "# так же применив 'stratify' для равномерного разделения значений в 'остаточной' выборке.\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "    features_remaining, target_remaining, test_size=0.5, random_state=12345, stratify=target_remaining)\n",
    "\n",
    "print(f'Размеры выборок:')\n",
    "print(f'Обучающая: {len(features_train)}')\n",
    "print(f'Валидационная: {len(features_valid)}')\n",
    "print(f'Тестовая: {len(features_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aead412-6094-48f9-b6ed-52711c24efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверим сохранение пропорций равномерного распределения значений в выборках\n",
    "for tr in [target_train, target_valid, target_test]:\n",
    "    print(tr.value_counts()/len(tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd6958f-b46f-49f7-821a-a35d03d3ae27",
   "metadata": {},
   "source": [
    "Исходные данные разделены на обучающую, валидационную и тестовую в отношении 3:1:1. С помощью метода 'stratify' соблюдены пропорции соотношения целевых признаков. \n",
    "\n",
    "Данные готовы к исследованию."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c105c6af-6253-4a67-a28f-92bd495a928d",
   "metadata": {},
   "source": [
    "# 3. Исследование качества моделей при изменении гиперпараметров."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55ed971-a77a-40cf-b8db-5f2b324030cb",
   "metadata": {},
   "source": [
    "Сравним по метрике accuracy модели: DecisionTreeClassifier, RandomForestClassifier, LogisticRegression с различными гиперпараметрами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab01c7d-c4e5-44bf-b580-e3bf33e0bc01",
   "metadata": {},
   "source": [
    "## 3.1 Модель DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa4cdac-b652-4da7-bba3-d293b5d93538",
   "metadata": {},
   "source": [
    "Создадим многоуровневый цикл перебирающий гиперпараметры применяемые к модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6c1860e-ca22-4336-bb82-47e008e336db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для удобства визуализации результатов создадим табличку, \n",
    "# которая выведет 5 наиболее оптимальных гиперпараметров для заданной модели \n",
    "columns = ['criterion', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'accuracy_score']\n",
    "data = []\n",
    "for criterion in ['gini', 'entropy']:\n",
    "    for max_depth in range(1, 21):\n",
    "        for min_samples_split in [0.01, 0.1]:\n",
    "            for min_samples_leaf in [0.0001, 0.001]:\n",
    "                model = DecisionTreeClassifier(criterion=criterion,\n",
    "                        max_depth=max_depth,\n",
    "                        min_samples_split=min_samples_split,\n",
    "                        min_samples_leaf=min_samples_leaf,\n",
    "                        random_state=12345)\n",
    "                \n",
    "                model.fit(features_train, target_train)\n",
    "                predictions = model.predict(features_valid)\n",
    "                 \n",
    "                score = accuracy_score(predictions, target_valid)\n",
    "                string = [criterion, max_depth, min_samples_split, min_samples_leaf,\n",
    "                         score]\n",
    "                data.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cb699bf-cb64-4b8a-bf24-2caa8041f1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим 5 лучших результатов работы модели\n",
    "tree_top_parameter = pd.DataFrame(columns=columns, data=data)\n",
    "print('5 лучших наборов гиперпараметров')\n",
    "tree_top_parameter.sort_values('accuracy_score', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0ff03b9-338c-4faf-b505-f2f93e87eccf",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим 5 худших результатов работы модели\n",
    "tree_top_parameter = pd.DataFrame(columns=columns, data=data)\n",
    "print('5 худших наборов гиперпараметров')\n",
    "tree_top_parameter.sort_values('accuracy_score', ascending = True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897b7ba4-9b27-4fd0-9e89-f8ab14231808",
   "metadata": {},
   "source": [
    "В наборах гиперпараметров использовались критерии: entropy и gini. Исходя из результатов, критерий энтропии оказывает наибольшее положительное влияние на лучшие наборы модели.\n",
    "\n",
    "При измерениях accuracy на валидационной выборке наилучшей максимальной глубиной явно является глубина, равная 9. Начиная со значения 10 и дальнейшее увеличение глубины дерева приводит к переобучению модели. Слишком маленькая глубина, менее 4, не позволила получить удовлетворительные результаты.\\\n",
    "Стоит обратить внимание, что min_samples_split и min_samples_leaf в данном случае практически равнозначно положительно повлияли на лучшие наборы модели.\n",
    "\n",
    "Подводя итоги применения данной модели, можно утверждать, что при решении поставленной задачи наиболее важным гиперпарамтром является максимальная глубина дерева, так как ее изменения в корне меняют конечный результат.\n",
    "\n",
    "Сохраним лучший результат.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88ebb5c3-86af-4045-862c-59ed301925ae",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tree = tree_top_parameter.sort_values('accuracy_score', ascending = False).head(1)\n",
    "best_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0b2f4f-f248-4f00-ae2c-d72e5700f171",
   "metadata": {},
   "source": [
    "## 3.2 Модель RandomForestClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593d5b96-33c3-4f13-99fb-b6b6279fc382",
   "metadata": {},
   "source": [
    "Так же создадим многоуровневый цикл перебирающий гиперпараметры применяемые к модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27653812-6d6c-4e3b-9bef-9791e8acc18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['n_estimators', 'class_weight', 'bootstrap', 'accuracy_score']\n",
    "data = []\n",
    "for n_estimators in range(1, 201, 20):\n",
    "    for class_weight in ['balanced', None]:\n",
    "        for bootstrap in [True, False]:\n",
    "            for min_samples_leaf in [0.0001, 0.001, 0.01]:\n",
    "                model = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                        class_weight=class_weight,\n",
    "                        bootstrap=bootstrap,\n",
    "                        random_state=12345)\n",
    "                \n",
    "                model.fit(features_train, target_train)\n",
    "                predictions = model.predict(features_valid)\n",
    "               \n",
    "                score = accuracy_score(predictions, target_valid)\n",
    "                string = [n_estimators, class_weight, bootstrap,\n",
    "                         score]\n",
    "                data.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ee2b59c-2e8e-4662-8fc3-88850a17e7a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим 5 лучших результатов работы модели\n",
    "forest_top_parameter = pd.DataFrame(columns=columns, data=data)\n",
    "print('5 лучших наборов гиперпараметров')\n",
    "forest_top_parameter.sort_values('accuracy_score', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a8afeb8-20e6-4c22-b0a4-47958dae48a7",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим 5 худших результатов работы модели\n",
    "forest_top_parameter = pd.DataFrame(columns=columns, data=data)\n",
    "print('5 худших наборов гиперпараметров')\n",
    "forest_top_parameter.sort_values('accuracy_score', ascending = True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc73d3bc-e857-48fc-9e1c-26bee53ec690",
   "metadata": {},
   "source": [
    "Качество модели RandomForestClassifier намного меньше зависит от подбора гиперпараметров, чем качество модели DecisionTreeClassifier.\n",
    "Как и ожидалось, качество модели случайного леса выше, однако скорость выполнения расчета низкая.\n",
    "\n",
    "Из результатов видно, что существенное влияние оказывает гиперпараметр bootstrap: так как во всех 'лучших' моделях он принимает значение True, однако и в худших присутствует.\n",
    "\n",
    "Бесконечное увеличение количества деревьев не приводит к улучшению качества модели: она переобучется. У лучшей модели не самое большое число n_estimators.\\\n",
    "Существенно улучшает 5 лучших наборов гиперпараметр минимального количества объектов в листе.\n",
    "\n",
    "Сохраним лучший результат модели случайного леса. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f47372c0-d797-4d68-bf59-572439e475dd",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf = forest_top_parameter.sort_values('accuracy_score', ascending = False).head(1)\n",
    "best_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223f53a8-bf4d-4c0e-87a0-04c0719d91a2",
   "metadata": {},
   "source": [
    "## 3.3 Модель LogisticRegression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cdd1a7-8483-49d0-981d-5477e9e50c5e",
   "metadata": {},
   "source": [
    "Создадим модель логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61522dda-5bcd-416e-9889-70724142c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000,\n",
    "        solver='lbfgs',\n",
    "        random_state=12345)\n",
    "                \n",
    "model.fit(features_train, target_train)\n",
    "predictions = model.predict(features_valid)\n",
    "               \n",
    "regression_score = accuracy_score(predictions, target_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3522ab36-e902-493c-9ab3-e033c78e34a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# посмотрим результат работы модели логистической регрессии\n",
    "print(f'Значение accuracy модели логистической регрессии:', regression_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b387eb3-55a5-499b-8b03-ff1344991bdd",
   "metadata": {},
   "source": [
    "Качество модели логистическая регрессия на валидационной выборке ниже, чем и у модели дерево решений, и у модели случайный лес.\n",
    "\n",
    "При работе с данной моделью были сделаны выводы, что изменение гиперпараметров модели, в значительной степени не влияют на качество предсказания модели. Влияние слабое и более разбросано. В коненчном итоге, результат либо приемлемый, либо плохой. Можно сделать вывод, что модель имеет тонкую грань к переобучению."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e1725f-e208-4938-8efa-87c3bdd60869",
   "metadata": {},
   "source": [
    "# 4. Проверка качества модели на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aec9e5d-5d90-4d82-a20e-0b7494618d9f",
   "metadata": {},
   "source": [
    "Выведем лучшие наборы гиперпараметров для каждого семейства моделей и соответсвующие им accuracy_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f92cffe4-1cb9-4cd4-8bce-c96bbd4873cf",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_results = pd.DataFrame({'Accuracy DecisionTreeClassifier': ['0.802'], 'Accuracy RandomForestClassifier' : ['0.811'], 'Accuracy LogisticRegression': ['0.738']})\n",
    "total_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8565e2-ecad-4db4-b174-3cca118e8ef6",
   "metadata": {},
   "source": [
    "Таким образом, наибольшего accuracy_score удалось добиться с помощью модели случайного леса (RandomForestClassifier) у дерева решений (DecisionTreeClassifier) так же корректный и достаточно близкий результат. Видимо, в связи с тем, что зависимость ответа от параметров не 'достаточно' линейная, модель регрессии использовать для данной выборки не совсем целесообразно.\n",
    "\n",
    "Проверим качество лучшей модели с заданными гиперпараметрами на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7aae412d-85fa-4a66-bb02-e52935d34a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=61,\n",
    "        class_weight=None,\n",
    "        bootstrap=True,\n",
    "        random_state=12345)\n",
    "\n",
    "model.fit(features_train, target_train)\n",
    "score = model.score(features_test, target_test)\n",
    "print('accuracy_score на тестовой выборке:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797eb64c-60a7-4e1c-b808-131a51a34239",
   "metadata": {},
   "source": [
    "На тестовой выборке accuracy_score оказался немного ниже, чем на валидационной, однако при увеличении числа деревьев точность увеличивается. Тем не менее, требование, указанное в задании (accuracy_score > 0.75) выполнено."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3418961-fde6-41f5-b15a-64df45d91d84",
   "metadata": {},
   "source": [
    "# 5. Проверка модели на вменяемость."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd8c997-2453-470d-a45b-aca151a5fdd2",
   "metadata": {},
   "source": [
    "При обучении с учителем простая проверка работоспособности состоит из сравнения своей оценки с простыми практическими правилами. DummyClassifier реализует несколько таких простых стратегий классификации:\n",
    "\n",
    "**stratified** - генерирует случайные прогнозы, соблюдая распределение классов обучающего набора.\\\n",
    "**most_frequent** - всегда предсказывает наиболее частую метку в обучающем наборе.\\\n",
    "**prior** - всегда предсказывает класс, который максимизирует предыдущий класс (как most_frequent) и predict_proba возвращает предыдущий класс.\\\n",
    "**uniform** - генерирует предсказания равномерно в случайном порядке.\\\n",
    "**constant** - всегда предсказывает постоянную метку, предоставленную пользователем. Основная мотивация этого метода — оценка F1, когда положительный класс находится в меньшинстве.\n",
    "\n",
    "Применим данный метод сравнения полученной оценки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b05b3248-c44b-4e3a-9fd0-f35c3b735e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy_score на тестовых данных:\", score)\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"uniform\", random_state = 12)\n",
    "dummy_clf.fit(features_train, target_train)\n",
    "print(\"accuracy_score на случайных 0 и 1:\", accuracy_score(dummy_clf.predict(features_test), target_test))\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\", random_state = 12)\n",
    "dummy_clf.fit(features_train, target_train)\n",
    "print(\"accuracy_score на стратифицированной выборке:\", accuracy_score(dummy_clf.predict(features_test), target_test))\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\", random_state = 12)\n",
    "dummy_clf.fit(features_train, target_train)\n",
    "print(\"accuracy_score на наиболее частых значениях:\", accuracy_score(dummy_clf.predict(features_test), target_test))\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"constant\", random_state = 12, constant = 0)\n",
    "dummy_clf.fit(features_train, target_train)\n",
    "print(\"accuracy_score на нулях:\", accuracy_score(dummy_clf.predict(features_test), target_test))\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"constant\", random_state = 12, constant = 1)\n",
    "dummy_clf.fit(features_train, target_train)\n",
    "print(\"accuracy_score на единицах:\", accuracy_score(dummy_clf.predict(features_test), target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42684630-41bf-4c48-a8fe-0f16ab886805",
   "metadata": {},
   "source": [
    "Обученная модель показывает себя лучше, чем все рассмотренные примтивы, а значит ее можно назвать адекватной."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2844db-90b6-4cfc-92ca-1b7f3410451b",
   "metadata": {},
   "source": [
    "# 6. Общий вывод."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceeb274-3726-45a3-ac2d-b687d56062e0",
   "metadata": {},
   "source": [
    "По результатам исследования можно сделать следующие выводы:\n",
    "\n",
    "Проведено исследование в целях разработки модели, позволяющей наиболее точно предложить пользователям мобильной связи тарифы «Смарт» или «Ультра».\\\n",
    "Модель построена на основании поведения клиентов, уже перешедших на эти тарифы.\n",
    "\n",
    "Были построены 3 модели:\n",
    "\n",
    "1) Дерево решений (Decision Tree Classifier).\n",
    "2) Cлучайный лес (RandomForestClassifier).\n",
    "3) Логистическая регрессия (Logistic Regression).\n",
    "   \n",
    "По результатам сравнения была выбрана лучшая - 'случайный лес' со следующими гиперпараметрами n_estimators=61, class_weight=None, bootstrap=True. Лучшее значение accuracy_score = 0.811.\n",
    "\n",
    "Из всех отработанных моделей только модель логистической регрессии не соответствуют требованию по качеству, согласно которому значение accuracy должно быть не менее 0.75.\n",
    "Лучшая модель проверена на тестовой выборке и получено значение accuracy = 0.8. \n",
    "Для проверки на адекватность нашей лучшей модели - случайный лес (RandomForestClassifier) была использована модель DummyClassifier, которая показала результат accuracy ниже, чем результат модели полученный в процессе исследования.\n",
    "\n",
    "Результаты исследования позволят специалистам использовать полученную нами модель, которая подберет клиентам пользующимся архивными тарифами -  новый. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed011f4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2857,
    "start_time": "2023-11-18T20:28:33.478Z"
   },
   {
    "duration": 69,
    "start_time": "2023-11-18T20:28:36.337Z"
   },
   {
    "duration": 11,
    "start_time": "2023-11-18T20:28:36.408Z"
   },
   {
    "duration": 20,
    "start_time": "2023-11-18T20:28:36.420Z"
   },
   {
    "duration": 23,
    "start_time": "2023-11-18T20:28:36.442Z"
   },
   {
    "duration": 5,
    "start_time": "2023-11-18T20:28:36.466Z"
   },
   {
    "duration": 15,
    "start_time": "2023-11-18T20:28:36.473Z"
   },
   {
    "duration": 5,
    "start_time": "2023-11-18T20:28:36.500Z"
   },
   {
    "duration": 16,
    "start_time": "2023-11-18T20:28:36.506Z"
   },
   {
    "duration": 8,
    "start_time": "2023-11-18T20:28:36.523Z"
   },
   {
    "duration": 1251,
    "start_time": "2023-11-18T20:28:36.532Z"
   },
   {
    "duration": 16,
    "start_time": "2023-11-18T20:28:37.785Z"
   },
   {
    "duration": 12,
    "start_time": "2023-11-18T20:28:37.802Z"
   },
   {
    "duration": 9,
    "start_time": "2023-11-18T20:28:37.817Z"
   },
   {
    "duration": 49496,
    "start_time": "2023-11-18T20:28:37.828Z"
   },
   {
    "duration": 11,
    "start_time": "2023-11-18T20:29:27.326Z"
   },
   {
    "duration": 12,
    "start_time": "2023-11-18T20:29:27.339Z"
   },
   {
    "duration": 15,
    "start_time": "2023-11-18T20:29:27.353Z"
   },
   {
    "duration": 61,
    "start_time": "2023-11-18T20:29:27.369Z"
   },
   {
    "duration": 4,
    "start_time": "2023-11-18T20:29:27.432Z"
   },
   {
    "duration": 16,
    "start_time": "2023-11-18T20:29:27.437Z"
   },
   {
    "duration": 250,
    "start_time": "2023-11-18T20:29:27.455Z"
   },
   {
    "duration": 14,
    "start_time": "2023-11-18T20:29:27.707Z"
   },
   {
    "duration": 52,
    "start_time": "2023-11-18T21:21:17.517Z"
   },
   {
    "duration": 7,
    "start_time": "2023-11-18T21:21:22.649Z"
   },
   {
    "duration": 1688,
    "start_time": "2023-11-18T21:21:27.074Z"
   },
   {
    "duration": 123,
    "start_time": "2023-11-18T21:21:28.764Z"
   },
   {
    "duration": 14,
    "start_time": "2023-11-18T21:21:28.888Z"
   },
   {
    "duration": 15,
    "start_time": "2023-11-18T21:21:28.904Z"
   },
   {
    "duration": 26,
    "start_time": "2023-11-18T21:21:28.922Z"
   },
   {
    "duration": 6,
    "start_time": "2023-11-18T21:21:28.950Z"
   },
   {
    "duration": 12,
    "start_time": "2023-11-18T21:21:28.957Z"
   },
   {
    "duration": 5,
    "start_time": "2023-11-18T21:21:28.970Z"
   },
   {
    "duration": 40,
    "start_time": "2023-11-18T21:21:28.977Z"
   },
   {
    "duration": 7,
    "start_time": "2023-11-18T21:21:29.019Z"
   },
   {
    "duration": 1361,
    "start_time": "2023-11-18T21:21:29.028Z"
   },
   {
    "duration": 20,
    "start_time": "2023-11-18T21:21:30.391Z"
   },
   {
    "duration": 16,
    "start_time": "2023-11-18T21:21:30.412Z"
   },
   {
    "duration": 26,
    "start_time": "2023-11-18T21:21:30.431Z"
   },
   {
    "duration": 50945,
    "start_time": "2023-11-18T21:21:30.459Z"
   },
   {
    "duration": 18,
    "start_time": "2023-11-18T21:22:21.405Z"
   },
   {
    "duration": 16,
    "start_time": "2023-11-18T21:22:21.425Z"
   },
   {
    "duration": 12,
    "start_time": "2023-11-18T21:22:21.443Z"
   },
   {
    "duration": 73,
    "start_time": "2023-11-18T21:22:21.457Z"
   },
   {
    "duration": 4,
    "start_time": "2023-11-18T21:22:21.531Z"
   },
   {
    "duration": 10,
    "start_time": "2023-11-18T21:22:21.536Z"
   },
   {
    "duration": 269,
    "start_time": "2023-11-18T21:22:21.548Z"
   },
   {
    "duration": 14,
    "start_time": "2023-11-18T21:22:21.819Z"
   },
   {
    "duration": 36,
    "start_time": "2023-11-18T21:22:50.938Z"
   },
   {
    "duration": 4,
    "start_time": "2023-11-18T21:22:54.392Z"
   },
   {
    "duration": 16,
    "start_time": "2023-11-18T21:22:58.271Z"
   },
   {
    "duration": 40,
    "start_time": "2023-11-18T21:23:02.954Z"
   },
   {
    "duration": 3,
    "start_time": "2023-11-18T21:23:05.163Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
